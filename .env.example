# Metis - Intelligent MCP Router & Web Based MCP Client
# Environment Configuration Template
# Copy this file to .env and fill in your actual values

# =============================================================================
# SHARED CONFIGURATION
# =============================================================================

# OpenAI API Configuration (Required for all components)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your_openai_api_key_here

# Application Environment
# Options: development, production, test
NODE_ENV=development
PYTHON_ENV=development

# Logging Configuration
# Options: debug, info, warn, error
LOG_LEVEL=info
LOG_FORMAT=text

# =============================================================================
# MCP SERVER CONFIGURATION (server/)
# =============================================================================

# Maximum number of MCP servers to keep active simultaneously
# Higher values provide more tools but increase context overhead
# Recommended: 3-5 for optimal performance
MAX_ACTIVE_SERVERS=3

# MCP Server Port
# Port for the intelligent MCP router HTTP server
SERVER_PORT=9999

# MCP Configuration File Path
# Path to the active server configuration file (relative to server directory)
MCP_CONFIG_PATH=./config.json

# OpenAI Model for Server Operations
# Model used for server selection and embeddings
OPENAI_MODEL=gpt-4o

# Cache and Performance Settings
CACHE_SIZE=100
REQUEST_TIMEOUT=30

# =============================================================================
# BACKEND CONFIGURATION (client/backend/)
# =============================================================================

# Backend Server Port
# Port for the FastAPI AI agent backend
BACKEND_PORT=8000

# Server Connection URL
# URL to connect to the MCP router server
SERVER_URL=http://localhost:9999

# Python Environment Settings
PYTHON_ENV=development

# Session Configuration
SESSION_TIMEOUT_MINUTES=30
CLEANUP_INTERVAL_SECONDS=300

# OpenAI Model for Backend Agent
# Model used for the AI agent conversations
OPENAI_MODEL=gpt-4o

# =============================================================================
# FRONTEND CONFIGURATION (client/frontend/)
# =============================================================================

# Frontend Server Port
# Port for the Next.js web interface
FRONTEND_PORT=3000

# Backend API URL
# URL to connect to the FastAPI backend (must be accessible from browser)
NEXT_PUBLIC_API_URL=http://localhost:8000

# Next.js Environment
NODE_ENV=development

# =============================================================================
# DOCKER CONFIGURATION
# =============================================================================

# Docker Network Name
DOCKER_NETWORK=metis-network

# Container Names
DOCKER_SERVER_CONTAINER=metis-server
DOCKER_BACKEND_CONTAINER=metis-backend
DOCKER_FRONTEND_CONTAINER=metis-frontend

# Volume Names
DOCKER_SERVER_DATA_VOLUME=metis-server-data
DOCKER_AUTH_DATA_VOLUME=metis-auth-data
DOCKER_NODE_MODULES_VOLUME=metis-node-modules

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# CORS Origins (comma-separated list)
# Origins allowed to access the backend API
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# API Rate Limiting
# Maximum requests per minute per IP
API_RATE_LIMIT=100

# =============================================================================
# DEVELOPMENT CONFIGURATION
# =============================================================================

# Hot Reload Settings
# Enable hot reloading for development
HOT_RELOAD=true

# Debug Settings
# Enable debug mode for additional logging
DEBUG=false

# Development Tools
# Enable development-specific features
DEV_TOOLS=true

# =============================================================================
# PRODUCTION CONFIGURATION
# =============================================================================

# Production optimizations (uncomment for production)
# NODE_ENV=production
# PYTHON_ENV=production
# LOG_LEVEL=warn
# LOG_FORMAT=json
# DEBUG=false
# HOT_RELOAD=false
# DEV_TOOLS=false

# Production URLs (update for your deployment)
# NEXT_PUBLIC_API_URL=https://your-backend-domain.com
# SERVER_URL=http://metis-server:9999
# CORS_ORIGINS=https://your-frontend-domain.com

# =============================================================================
# OPTIONAL CONFIGURATION
# =============================================================================

# Custom MCP Registry Path
# Path to custom MCP server registry file
# MCP_REGISTRY_PATH=./custom-registry.json

# Authentication Directory
# Directory for MCP server authentication credentials
# MCP_AUTH_DIR=~/.mcp-auth

# Custom Build Settings
# BUILD_TARGET=production
# OPTIMIZE_IMAGES=true
# ENABLE_COMPRESSION=true

# Monitoring and Analytics
# ENABLE_METRICS=false
# METRICS_PORT=9090
# HEALTH_CHECK_INTERVAL=30

# =============================================================================
# NOTES
# =============================================================================

# 1. OPENAI_API_KEY is required for the application to function
# 2. Ports 3000, 8000, and 9999 must be available
# 3. MAX_ACTIVE_SERVERS controls memory usage vs available tools
# 4. For Docker deployment, use service names instead of localhost
# 5. Environment variables are loaded from this file by all components
# 6. Sensitive values should never be committed to version control